"""
ë°ì´í„° ê²€ì¦ ì‹œìŠ¤í…œ - 1ë‹¨ê³„ í”„ë¡œì íŠ¸
ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ë¼ì´ë¸ŒëŸ¬ë¦¬ êµ¬í˜„

ì£¼ìš” ê¸°ëŠ¥:
- CSV ë°ì´í„° ê²€ì¦
- ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
- ì»¤ìŠ¤í…€ ì˜ˆì™¸ ì²˜ë¦¬
- ì•ˆì „í•œ íŒŒì¼ ì²˜ë¦¬
"""

import pandas as pd
import json
import time
import psutil
import os
from typing import Dict, Any, List, Optional
from functools import wraps
from contextlib import contextmanager


# 1. ì»¤ìŠ¤í…€ ì˜ˆì™¸ í´ë˜ìŠ¤ë“¤
class DataValidationError(Exception):
    """ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨ ì‹œ ë°œìƒí•˜ëŠ” ì˜ˆì™¸"""
    pass


class ConfigurationError(Exception):
    """ì„¤ì • íŒŒì¼ ê´€ë ¨ ì˜ˆì™¸"""
    pass


class FileProcessingError(Exception):
    """íŒŒì¼ ì²˜ë¦¬ ê´€ë ¨ ì˜ˆì™¸"""
    pass


# 2. ì„±ëŠ¥ ì¸¡ì • ë°ì½”ë ˆì´í„°
def performance_monitor(func):
    """í•¨ìˆ˜ ì‹¤í–‰ ì‹œê°„ ë° ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì • ë°ì½”ë ˆì´í„°"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        # ì‹œì‘ ì‹œê°„ ë° ë©”ëª¨ë¦¬
        start_time = time.time()
        process = psutil.Process(os.getpid())
        start_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        try:
            result = func(*args, **kwargs)
            
            # ì¢…ë£Œ ì‹œê°„ ë° ë©”ëª¨ë¦¬
            end_time = time.time()
            end_memory = process.memory_info().rss / 1024 / 1024  # MB
            
            # ì„±ëŠ¥ ì •ë³´ ì¶œë ¥
            execution_time = end_time - start_time
            memory_used = end_memory - start_memory
            
            print(f"\nğŸ“Š [{func.__name__}] ì„±ëŠ¥ ë¦¬í¬íŠ¸:")
            print(f"   â±ï¸  ì‹¤í–‰ì‹œê°„: {execution_time:.2f}ì´ˆ")
            print(f"   ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©: {memory_used:.2f}MB")
            print(f"   ğŸ“ˆ ìµœëŒ€ ë©”ëª¨ë¦¬: {end_memory:.2f}MB")
            
            return result
            
        except Exception as e:
            end_time = time.time()
            print(f"\nâŒ [{func.__name__}] ì‹¤í–‰ ì‹¤íŒ¨:")
            print(f"   â±ï¸  ì‹¤í–‰ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
            print(f"   ğŸš« ì—ëŸ¬: {str(e)}")
            raise
    
    return wrapper


# 3. íŒŒì¼ ì•ˆì „ ì²˜ë¦¬ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €
@contextmanager
def safe_file_handler(file_path: str, mode: str = 'r', encoding: str = 'utf-8'):
    """ì•ˆì „í•œ íŒŒì¼ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
    file_obj = None
    try:
        if not os.path.exists(file_path) and 'r' in mode:
            raise FileProcessingError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        
        file_obj = open(file_path, mode, encoding=encoding)
        print(f"âœ… íŒŒì¼ ì—´ê¸° ì„±ê³µ: {file_path}")
        yield file_obj
        
    except IOError as e:
        raise FileProcessingError(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    finally:
        if file_obj:
            file_obj.close()
            print(f"ğŸ”’ íŒŒì¼ ì•ˆì „í•˜ê²Œ ë‹«ìŒ: {file_path}")


# 4. ë©”ì¸ ë°ì´í„° ê²€ì¦ í´ë˜ìŠ¤
class DataValidator:
    """ë°ì´í„° í’ˆì§ˆ ê²€ì¦ì„ ìœ„í•œ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self, config_path: str):
        """
        DataValidator ì´ˆê¸°í™”
        
        Args:
            config_path: ê²€ì¦ ê·œì¹™ì´ ì •ì˜ëœ JSON ì„¤ì • íŒŒì¼ ê²½ë¡œ
        """
        self.config_path = config_path
        self._validation_rules = None
        self._load_config()
    
    def _load_config(self):
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        try:
            with safe_file_handler(self.config_path, 'r') as f:
                self._validation_rules = json.load(f)
            print(f"ğŸ“‹ ì„¤ì • íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {len(self._validation_rules)} ê°œ ê·œì¹™")
        except (FileProcessingError, json.JSONDecodeError) as e:
            raise ConfigurationError(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
    
    @property
    def validation_rules(self) -> Dict[str, Any]:
        """ê²€ì¦ ê·œì¹™ ë°˜í™˜ (ì½ê¸° ì „ìš©)"""
        return self._validation_rules.copy() if self._validation_rules else {}
    
    @performance_monitor
    def validate_dataset(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        ë°ì´í„°ì…‹ ì „ì²´ ê²€ì¦ ìˆ˜í–‰
        
        Args:
            df: ê²€ì¦í•  pandas DataFrame
            
        Returns:
            ê²€ì¦ ê²°ê³¼ ë¦¬í¬íŠ¸ ë”•ì…”ë„ˆë¦¬
        """
        if df.empty:
            raise DataValidationError("ë¹ˆ ë°ì´í„°ì…‹ì€ ê²€ì¦í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        report = {
            "ì´_í–‰ìˆ˜": len(df),
            "ì´_ì—´ìˆ˜": len(df.columns),
            "ê²€ì¦_í†µê³¼": True,
            "ì˜¤ë¥˜_ëª©ë¡": [],
            "ê²½ê³ _ëª©ë¡": [],
            "ì»¬ëŸ¼ë³„_ë¦¬í¬íŠ¸": {}
        }
        
        # ê° ì»¬ëŸ¼ë³„ ê²€ì¦ ìˆ˜í–‰
        for column in df.columns:
            column_report = self._validate_column(df, column)
            report["ì»¬ëŸ¼ë³„_ë¦¬í¬íŠ¸"][column] = column_report
            
            if column_report["ì˜¤ë¥˜_ê°œìˆ˜"] > 0:
                report["ê²€ì¦_í†µê³¼"] = False
                report["ì˜¤ë¥˜_ëª©ë¡"].extend(column_report["ì˜¤ë¥˜_ëª©ë¡"])
            
            if column_report["ê²½ê³ _ê°œìˆ˜"] > 0:
                report["ê²½ê³ _ëª©ë¡"].extend(column_report["ê²½ê³ _ëª©ë¡"])
        
        return report
    
    def _validate_column(self, df: pd.DataFrame, column: str) -> Dict[str, Any]:
        """ê°œë³„ ì»¬ëŸ¼ ê²€ì¦"""
        series = df[column]
        rules = self._validation_rules.get(column, {})
        
        column_report = {
            "ë°ì´í„°_íƒ€ì…": str(series.dtype),
            "null_ê°œìˆ˜": series.isnull().sum(),
            "ìœ ë‹ˆí¬_ê°’_ê°œìˆ˜": series.nunique(),
            "ì˜¤ë¥˜_ê°œìˆ˜": 0,
            "ê²½ê³ _ê°œìˆ˜": 0,
            "ì˜¤ë¥˜_ëª©ë¡": [],
            "ê²½ê³ _ëª©ë¡": []
        }
        
        # Null ê°’ ê²€ì¦
        if rules.get("required", False) and column_report["null_ê°œìˆ˜"] > 0:
            error_msg = f"{column}: í•„ìˆ˜ ì»¬ëŸ¼ì— {column_report['null_ê°œìˆ˜']}ê°œì˜ null ê°’ ì¡´ì¬"
            column_report["ì˜¤ë¥˜_ëª©ë¡"].append(error_msg)
            column_report["ì˜¤ë¥˜_ê°œìˆ˜"] += 1
        
        # ë°ì´í„° íƒ€ì… ê²€ì¦
        expected_type = rules.get("type")
        if expected_type and not self._check_data_type(series, expected_type):
            error_msg = f"{column}: ì˜ˆìƒ íƒ€ì… {expected_type}, ì‹¤ì œ íƒ€ì… {series.dtype}"
            column_report["ì˜¤ë¥˜_ëª©ë¡"].append(error_msg)
            column_report["ì˜¤ë¥˜_ê°œìˆ˜"] += 1
        
        # ë²”ìœ„ ê²€ì¦ (ìˆ«ìí˜• ë°ì´í„°)
        if series.dtype in ['int64', 'float64'] and 'range' in rules:
            min_val, max_val = rules['range']
            out_of_range = series[(series < min_val) | (series > max_val)].count()
            if out_of_range > 0:
                warning_msg = f"{column}: {out_of_range}ê°œ ê°’ì´ ë²”ìœ„ [{min_val}, {max_val}]ë¥¼ ë²—ì–´ë‚¨"
                column_report["ê²½ê³ _ëª©ë¡"].append(warning_msg)
                column_report["ê²½ê³ _ê°œìˆ˜"] += 1
        
        return column_report
    
    def _check_data_type(self, series: pd.Series, expected_type: str) -> bool:
        """ë°ì´í„° íƒ€ì… ê²€ì¦ í—¬í¼"""
        type_mapping = {
            'integer': series.dtype in ['int64', 'int32'],
            'float': series.dtype in ['float64', 'float32'],
            'string': series.dtype == 'object',
            'boolean': series.dtype == 'bool'
        }
        return type_mapping.get(expected_type, True)
    
    @performance_monitor
    def save_report(self, report: Dict[str, Any], output_path: str):
        """ê²€ì¦ ë¦¬í¬íŠ¸ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        try:
            with safe_file_handler(output_path, 'w') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ: {output_path}")
        except FileProcessingError as e:
            raise DataValidationError(f"ë¦¬í¬íŠ¸ ì €ì¥ ì‹¤íŒ¨: {str(e)}")


# 5. ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜
@performance_monitor
def process_large_dataset(file_path: str, chunk_size: int = 10000) -> Dict[str, Any]:
    """
    ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ì„ ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
    
    Args:
        file_path: ì²˜ë¦¬í•  CSV íŒŒì¼ ê²½ë¡œ
        chunk_size: ì²­í¬ í¬ê¸°
        
    Returns:
        ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½
    """
    summary = {
        "ì´_ì²˜ë¦¬_í–‰ìˆ˜": 0,
        "ì²­í¬_ê°œìˆ˜": 0,
        "ì²˜ë¦¬_ì‹œê°„": 0,
        "ì—ëŸ¬_ê°œìˆ˜": 0
    }
    
    try:
        # CSV íŒŒì¼ì„ ì²­í¬ ë‹¨ìœ„ë¡œ ì½ê¸°
        chunk_iter = pd.read_csv(file_path, chunksize=chunk_size)
        
        for chunk_idx, chunk in enumerate(chunk_iter):
            try:
                # ê° ì²­í¬ ì²˜ë¦¬ (ì˜ˆ: ê¸°ë³¸ì ì¸ ì •ì œ ì‘ì—…)
                processed_chunk = chunk.dropna().drop_duplicates()
                
                summary["ì´_ì²˜ë¦¬_í–‰ìˆ˜"] += len(processed_chunk)
                summary["ì²­í¬_ê°œìˆ˜"] += 1
                
                print(f"âœ… ì²­í¬ {chunk_idx + 1} ì²˜ë¦¬ ì™„ë£Œ: {len(processed_chunk)} í–‰")
                
            except Exception as e:
                summary["ì—ëŸ¬_ê°œìˆ˜"] += 1
                print(f"âŒ ì²­í¬ {chunk_idx + 1} ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
        
        return summary
        
    except FileNotFoundError:
        raise FileProcessingError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
    except Exception as e:
        raise DataValidationError(f"ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    print("ğŸš€ ë°ì´í„° ê²€ì¦ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # í…ŒìŠ¤íŠ¸ìš© ì„¤ì • íŒŒì¼ ìƒì„±
    config = {
        "name": {"required": True, "type": "string"},
        "age": {"required": True, "type": "integer", "range": [0, 120]},
        "salary": {"required": False, "type": "float", "range": [0, 1000000]}
    }
    
    config_path = "/Users/mzc03-minjeong/Documents/l&l/py/validation_config.json"
    with safe_file_handler(config_path, 'w') as f:
        json.dump(config, f, indent=2)
    
    # í…ŒìŠ¤íŠ¸ìš© ë°ì´í„° ìƒì„±
    test_data = pd.DataFrame({
        'name': ['Alice', 'Bob', None, 'Diana'],
        'age': [25, 30, 35, 150],  # 150ì€ ë²”ìœ„ ì´ˆê³¼
        'salary': [50000, 60000, 70000, 80000]
    })
    
    # DataValidator í…ŒìŠ¤íŠ¸
    try:
        validator = DataValidator(config_path)
        report = validator.validate_dataset(test_data)
        
        print("\nğŸ“‹ ê²€ì¦ ë¦¬í¬íŠ¸:")
        print(f"ê²€ì¦ í†µê³¼: {'âœ…' if report['ê²€ì¦_í†µê³¼'] else 'âŒ'}")
        print(f"ì´ ì˜¤ë¥˜: {len(report['ì˜¤ë¥˜_ëª©ë¡'])}ê°œ")
        print(f"ì´ ê²½ê³ : {len(report['ê²½ê³ _ëª©ë¡'])}ê°œ")
        
        # ë¦¬í¬íŠ¸ ì €ì¥
        report_path = "/Users/mzc03-minjeong/Documents/l&l/py/validation_report.json"
        validator.save_report(report, report_path)
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")